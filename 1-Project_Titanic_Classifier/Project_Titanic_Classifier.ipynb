{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5MrBC530gmg5"
   },
   "source": [
    "Let's start with your project: \n",
    "\n",
    "Are you a data scientist? \n",
    "\n",
    "I think you are an awesome a data scientist.\n",
    "\n",
    "### **Problem** \n",
    "**Our goal is to create a predictive model that can answer the following question:**\n",
    "\n",
    "**What kind of people had a better chance of surviving?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qhBfwzBgioTD"
   },
   "source": [
    "**Data about passengers:**\n",
    "*   Name\n",
    "*   Age\n",
    "*   Gender.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIEH8iZqi-sk"
   },
   "source": [
    "## Install and Import Libraries\n",
    "Let's install PySpark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oj1HhvIOY5Yz"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "# importing libraries\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDp80mG9jmfU"
   },
   "source": [
    "## Build Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ttzML9fpjE5a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/04 10:48:05 WARN Utils: Your hostname, yousri-Lenovo-Legion-5-15IMH05H resolves to a loopback address: 127.0.1.1; using 172.16.2.196 instead (on interface wlp0s20f3)\n",
      "21/11/04 10:48:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.0.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/11/04 10:48:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/11/04 10:48:06 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Practical-01-Yousri').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TiqECDzLj1Mg"
   },
   "source": [
    "## Data Loading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vn-hxNggkTqV"
   },
   "source": [
    "You have two datasets: \n",
    "* Train  \n",
    "* Test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8-A8M7QmKDJ"
   },
   "source": [
    "Read two datasets: \n",
    "* Train\n",
    "* Test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (StructType, StructField,\n",
    "                               StringType, IntegerType, DoubleType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FloatType' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4743/2002782828.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                           \u001b[0mStructField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Ticket'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStringType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                           \u001b[0mStructField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fare'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIntegerType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                           \u001b[0mStructField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cabin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFloatType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                           \u001b[0mStructField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Embarked'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStringType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                          ])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FloatType' is not defined"
     ]
    }
   ],
   "source": [
    "# recordSchema = StructType([StructField('PassengerId', IntegerType(), True),\n",
    "#                            StructField('Survived', IntegerType(), True),\n",
    "#                            StructField('Pclass', IntegerType(), True),\n",
    "#                           StructField('Name', StringType(), True),\n",
    "#                           StructField('Sex', StringType(), True),\n",
    "#                           StructField('Age', IntegerType(), True),\n",
    "#                           StructField('SibSp', IntegerType(), True),\n",
    "#                           StructField('Parch', IntegerType(), True),\n",
    "#                           StructField('Ticket', StringType(), True),\n",
    "#                           StructField('Fare', IntegerType(), True),\n",
    "#                           StructField('Cabin', FloatType(), True),\n",
    "#                           StructField('Embarked', StringType(), True),\n",
    "#                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Mx2qAccBk15y"
   },
   "outputs": [],
   "source": [
    "df_train = spark.read.csv('train.csv',header = True,inferSchema=True)\n",
    "df_test = spark.read.csv('test.csv',header = True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lj2ANTnWmSCq"
   },
   "source": [
    "Let's work with train dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5mWJR30lNs5"
   },
   "source": [
    "**Confirm if this is a dataframe or not:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "tEYTePrzk9yl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvLJElPrlT4i"
   },
   "source": [
    "**Show 5 rows.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "jYwhqvV8lnO0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(PassengerId=1, Survived=0, Pclass=3, Name='Braund, Mr. Owen Harris', Sex='male', Age=22.0, SibSp=1, Parch=0, Ticket='A/5 21171', Fare=7.25, Cabin=None, Embarked='S'),\n",
       " Row(PassengerId=2, Survived=1, Pclass=1, Name='Cumings, Mrs. John Bradley (Florence Briggs Thayer)', Sex='female', Age=38.0, SibSp=1, Parch=0, Ticket='PC 17599', Fare=71.2833, Cabin='C85', Embarked='C'),\n",
       " Row(PassengerId=3, Survived=1, Pclass=3, Name='Heikkinen, Miss. Laina', Sex='female', Age=26.0, SibSp=0, Parch=0, Ticket='STON/O2. 3101282', Fare=7.925, Cabin=None, Embarked='S'),\n",
       " Row(PassengerId=4, Survived=1, Pclass=1, Name='Futrelle, Mrs. Jacques Heath (Lily May Peel)', Sex='female', Age=35.0, SibSp=1, Parch=0, Ticket='113803', Fare=53.1, Cabin='C123', Embarked='S'),\n",
       " Row(PassengerId=5, Survived=0, Pclass=3, Name='Allen, Mr. William Henry', Sex='male', Age=35.0, SibSp=0, Parch=0, Ticket='373450', Fare=8.05, Cabin=None, Embarked='S')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QIYVxRXlnnw"
   },
   "source": [
    "**Display schema for the dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "pcvERiICl1Ep"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.printSchema()\n",
    "df_test.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmE3Wd80l1S6"
   },
   "source": [
    "**Statistical summary:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "cNY0SItol5Mo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|summary|      PassengerId|           Survived|            Pclass|                Name|   Sex|               Age|             SibSp|              Parch|            Ticket|             Fare|Cabin|Embarked|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|  count|              891|                891|               891|                 891|   891|               714|               891|                891|               891|              891|  204|     889|\n",
      "|   mean|            446.0| 0.3838383838383838| 2.308641975308642|                null|  null| 29.69911764705882|0.5230078563411896|0.38159371492704824|260318.54916792738| 32.2042079685746| null|    null|\n",
      "| stddev|257.3538420152301|0.48659245426485753|0.8360712409770491|                null|  null|14.526497332334035|1.1027434322934315| 0.8060572211299488|471609.26868834975|49.69342859718089| null|    null|\n",
      "|    min|                1|                  0|                 1|\"Andersson, Mr. A...|female|              0.42|                 0|                  0|            110152|              0.0|  A10|       C|\n",
      "|    max|              891|                  1|                 3|van Melkebeke, Mr...|  male|              80.0|                 8|                  6|         WE/P 5735|         512.3292|    T|       S|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+--------------------+------+------------------+-----------------+------------------+------------------+-----------------+-----+--------+\n",
      "|summary|       PassengerId|          Survived|            Pclass|                Name|   Sex|               Age|            SibSp|             Parch|            Ticket|             Fare|Cabin|Embarked|\n",
      "+-------+------------------+------------------+------------------+--------------------+------+------------------+-----------------+------------------+------------------+-----------------+-----+--------+\n",
      "|  count|               438|               438|               438|                 438|   438|               350|              438|               438|               438|              438|  104|     437|\n",
      "|   mean|             219.5|0.3721461187214612|2.2831050228310503|                null|  null|30.855485714285713| 0.45662100456621| 0.365296803652968|228762.85970149253|32.04006803652967| null|    null|\n",
      "| stddev|126.58396422928143|0.4839298099728147| 0.851563345160767|                null|  null|14.884232312749964|1.020023555036897|0.8139972722947301| 416628.4618395599|50.40455507146085| null|    null|\n",
      "|    min|                 1|                 0|                 1|\"Angle, Mrs. Will...|female|              0.42|                0|                 0|            110152|              0.0|  A10|       C|\n",
      "|    25%|               110|                 0|                 1|                null|  null|              21.0|                0|                 0|           17453.0|           7.8958| null|    null|\n",
      "|    50%|               219|                 0|                 3|                null|  null|              30.0|                0|                 0|          113807.0|          14.4542| null|    null|\n",
      "|    75%|               329|                 1|                 3|                null|  null|              39.0|                1|                 0|          348121.0|           31.275| null|    null|\n",
      "|    max|               438|                 1|                 3|van Melkebeke, Mr...|  male|              80.0|                8|                 6|         WE/P 5735|         512.3292|   F4|       S|\n",
      "+-------+------------------+------------------+------------------+--------------------+------+------------------+-----------------+------------------+------------------+-----------------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HiFaIEQTl70_"
   },
   "source": [
    "## EDA - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSNPOnP8mw2Q"
   },
   "source": [
    "**Display count for the train dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "zrtpG11Fl9HM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_6nnTfxm9_x"
   },
   "source": [
    "**Can you answer this question:** \n",
    "\n",
    "**How many people survived, and how many didn't survive?** \n",
    "\n",
    "**Please save data in a variable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Survived',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Cabin',\n",
       " 'Embarked']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "QDoqPwyomYxA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342 549\n"
     ]
    }
   ],
   "source": [
    "survived_True = df_train.where((col(\"Survived\") == 1).alias('Survived Bool')).count()\n",
    "survived_False = df_train.count() - survived_True\n",
    "print(survived_True, survived_False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Survived|count|\n",
      "+--------+-----+\n",
      "|       1|  342|\n",
      "|       0|  549|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "survived_count = df_train.groupBy('Survived').count()\n",
    "survived_count.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ygsg7wQqor9a"
   },
   "source": [
    "**Can you display your answer in ratio form?(Hint: Use \"UDF\" Function. (Hint: Use \"UDF\" Function. This is a hint you can use any method.)**\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "3uiaN29PoQnf"
   },
   "outputs": [],
   "source": [
    "# import org.apache.spark.sql.functions.udf package\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ratio(df):\n",
    "#     return df.select(col('count')).take()/df.agg({'count' : 'sum'}).take(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+----------+\n",
      "|Survived|count|ratio     |\n",
      "+--------+-----+----------+\n",
      "|1       |342  |0.3838384 |\n",
      "|0       |549  |0.61616164|\n",
      "+--------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total = df_train.count()\n",
    "@udf(returnType=FloatType()) \n",
    "def ratio(num):\n",
    "    return num/total\n",
    "\n",
    "survived_count.withColumn(\"ratio\", ratio(col(\"count\"))).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7Aker_lp1h4"
   },
   "source": [
    "**Can you get the number of males and females?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "XllkDlo3ongJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|   Sex|count|\n",
      "+------+-----+\n",
      "|female|  314|\n",
      "|  male|  577|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sex_count = df_train.groupBy('Sex').count()\n",
    "sex_count.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHFaJ15zqtEV"
   },
   "source": [
    "**1. What is the average number of survivors of each gender?**\n",
    "\n",
    "**2. What is the number of survivors of each gender?**\n",
    "\n",
    "(Hint: Group by the \"sex\" column. This is a hint you can use any method.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "NUikH7MUqdKq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|   Sex|count|\n",
      "+------+-----+\n",
      "|female|  314|\n",
      "|  male|  577|\n",
      "+------+-----+\n",
      "\n",
      "+------+--------+-----+\n",
      "|   Sex|Survived|count|\n",
      "+------+--------+-----+\n",
      "|  male|       0|  468|\n",
      "|female|       1|  233|\n",
      "|female|       0|   81|\n",
      "|  male|       1|  109|\n",
      "+------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get survived by gender:\n",
    "sex_count = df_train.groupBy(['Sex']).count()\n",
    "sex_count.show()\n",
    "\n",
    "# get survived by gender:\n",
    "survived_sex_count = df_train.groupBy(['Sex','Survived']).count()\n",
    "survived_sex_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314 577\n"
     ]
    }
   ],
   "source": [
    "females= sex_count.take(2)[0][1]\n",
    "males= sex_count.take(2)[1][1]\n",
    "print(females , males)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----+----------+\n",
      "|Sex   |Survived|count|ratio     |\n",
      "+------+--------+-----+----------+\n",
      "|male  |0       |468  |0.5252525 |\n",
      "|female|1       |233  |0.26150393|\n",
      "|female|0       |81   |0.09090909|\n",
      "|male  |1       |109  |0.12233446|\n",
      "+------+--------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "survived_sex_count.withColumn(\"ratio\", ratio(col(\"count\"))).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCEdYNdArtRN"
   },
   "source": [
    "**Create temporary view PySpark:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "YjlK6HDUqsI5"
   },
   "outputs": [],
   "source": [
    "df_train.createOrReplaceTempView('Temp_view')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXNePifnshHr"
   },
   "source": [
    "**How many people survived, and how many didn't survive? By SQL:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "0HxfPRTMslqk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Survived|Count|\n",
      "+--------+-----+\n",
      "|       1|  342|\n",
      "|       0|  549|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT Survived,COUNT(Survived) AS Count FROM Temp_view GROUP BY Survived').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVCdY6EasFWV"
   },
   "source": [
    "**Can you display the number of survivors from each gender as a ratio?**\n",
    "\n",
    "(Hint: Group by \"sex\" column. This is a hint you can use any method.)\n",
    "\n",
    "**Can you do this via SQL?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "7xQc3pUUr3HF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+\n",
      "|   SEX|              Count|\n",
      "+------+-------------------+\n",
      "|female| 0.7420382165605095|\n",
      "|  male|0.18890814558058924|\n",
      "+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT SEX,SUM(Survived)/COUNT(Survived) AS Count FROM Temp_view GROUP BY SEX').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6QXc5V8uu3Y"
   },
   "source": [
    "**Display a ratio for \"p-class\": SUM(Survived)/count for p-class**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "Mscs2mDFdFsD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+\n",
      "|Pclass|              Count|\n",
      "+------+-------------------+\n",
      "|     1| 0.6296296296296297|\n",
      "|     3|0.24236252545824846|\n",
      "|     2|0.47282608695652173|\n",
      "+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT Pclass, SUM(Survived)/COUNT(Pclass) AS Count FROM Temp_view GROUP BY Pclass').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EX0klxwAvg6J"
   },
   "source": [
    "**Let's take a break and continue after this.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ctM9t8atxJl"
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CfanZTCt6Wk"
   },
   "source": [
    "**First and foremost, we must merge both the train and test datasets. (Hint: The union function can do this.)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "id": "8Nm8S1K0r4uY"
   },
   "outputs": [],
   "source": [
    "combined = df_train.union(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jI7AD8FLz3iO"
   },
   "source": [
    "**Display count:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "s_WERAL8wvJa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1329"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5R4Miuy0z_uP"
   },
   "source": [
    "**Can you define the number of null values in each column?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBX8cJ000aqe"
   },
   "source": [
    "**Create Dataframe for null values**\n",
    "\n",
    "1. Column\n",
    "2. Number of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "id": "0LMOalKBxhpD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|          0|       0|     0|   0|  0|265|    0|    0|     0|   0| 1021|       3|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined.select([count(when(isnull(c), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cuKrOi5a0-Ma"
   },
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVQlr9vDy7Y4"
   },
   "source": [
    "**Create Temporary view PySpark:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "id": "xs3yeXhGI8rv"
   },
   "outputs": [],
   "source": [
    "combined.createOrReplaceTempView('df_temp_view')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Txa8NZIO1JaP"
   },
   "source": [
    "**Can you show the \"name\" column from your temporary table?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "m7yXqJoJy35k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                Name|\n",
      "+--------------------+\n",
      "|Braund, Mr. Owen ...|\n",
      "|Cumings, Mrs. Joh...|\n",
      "|Heikkinen, Miss. ...|\n",
      "|Futrelle, Mrs. Ja...|\n",
      "|Allen, Mr. Willia...|\n",
      "|    Moran, Mr. James|\n",
      "|McCarthy, Mr. Tim...|\n",
      "|Palsson, Master. ...|\n",
      "|Johnson, Mrs. Osc...|\n",
      "|Nasser, Mrs. Nich...|\n",
      "|Sandstrom, Miss. ...|\n",
      "|Bonnell, Miss. El...|\n",
      "|Saundercock, Mr. ...|\n",
      "|Andersson, Mr. An...|\n",
      "|Vestrom, Miss. Hu...|\n",
      "|Hewlett, Mrs. (Ma...|\n",
      "|Rice, Master. Eugene|\n",
      "|Williams, Mr. Cha...|\n",
      "|Vander Planke, Mr...|\n",
      "|Masselmani, Mrs. ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT Name From df_temp_view\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3F0F9cTZ2Cuz"
   },
   "source": [
    "**Run this code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "0kx6OcB-2BBT"
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "combined = combined.withColumn('Title',F.regexp_extract(F.col(\"Name\"),\"([A-Za-z]+)\\.\",1))\n",
    "combined.createOrReplaceTempView('combined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbZeUWS12r59"
   },
   "source": [
    "**Display \"Title\" column and count \"Title\" column:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "id": "hGkFMtlp1FAI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|   Title|Count|\n",
      "+--------+-----+\n",
      "|     Mme|    1|\n",
      "|     Don|    1|\n",
      "|      Ms|    1|\n",
      "|Countess|    2|\n",
      "|    Lady|    2|\n",
      "|    Capt|    2|\n",
      "|Jonkheer|    2|\n",
      "|     Sir|    2|\n",
      "|   Major|    3|\n",
      "|    Mlle|    4|\n",
      "|     Col|    4|\n",
      "|     Rev|    9|\n",
      "|      Dr|   11|\n",
      "|  Master|   56|\n",
      "|     Mrs|  186|\n",
      "|    Miss|  257|\n",
      "|      Mr|  786|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#spark.sql('SELECT Title,COUNT(Title) AS Count FROM combined GROUP BY TITLE').show()\n",
    "spark.sql('SELECT Title,COUNT(Title) AS Count FROM combined GROUP BY TITLE ORDER BY Count').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLBQDKYu4JOa"
   },
   "source": [
    "**We can see that Dr, Rev, Major, Col, Mlle, Capt, Don, Jonkheer, Countess, Ms, Sir, Lady, and Mme are really rare titles, so create Dictionary and set the value to \"rare\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Miss',\n",
       " 'Mr',\n",
       " 'Mlle',\n",
       " 'Don',\n",
       " 'Lady',\n",
       " 'Col',\n",
       " 'Major',\n",
       " 'Sir',\n",
       " 'Ms',\n",
       " 'Countess',\n",
       " 'Mrs',\n",
       " 'Capt',\n",
       " 'Rev',\n",
       " 'Dr',\n",
       " 'Jonkheer',\n",
       " 'Mme',\n",
       " 'Master']"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#title_map = \n",
    "all_titles = combined.select(F.collect_list('Title')).first()[0]\n",
    "all_titles = list(set(my_list))\n",
    "all_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Miss': 'not rare',\n",
       " 'Mr': 'not rare',\n",
       " 'Mlle': 'rare',\n",
       " 'Don': 'rare',\n",
       " 'Lady': 'rare',\n",
       " 'Col': 'rare',\n",
       " 'Major': 'rare',\n",
       " 'Sir': 'rare',\n",
       " 'Ms': 'rare',\n",
       " 'Countess': 'rare',\n",
       " 'Mrs': 'not rare',\n",
       " 'Capt': 'rare',\n",
       " 'Rev': 'rare',\n",
       " 'Dr': 'rare',\n",
       " 'Jonkheer': 'rare',\n",
       " 'Mme': 'rare',\n",
       " 'Master': 'not rare'}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_map = {title : 'rare' if title in title_list else 'not rare' for title in all_titles }\n",
    "titles_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wrE95Cv7Oqh"
   },
   "source": [
    "**Run the function:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "id": "HdDbWuDl7Pf4"
   },
   "outputs": [],
   "source": [
    "def impute_title(title):\n",
    "    return titles_map[title]# Title_map is your dictionary. please change this name with your dictionary name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'not rare'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test:\n",
    "impute_title('Miss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5EQVIhK7a9R"
   },
   "source": [
    "**Apply the function on \"Title\" column using UDF:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "id": "rBAiIOn77XFa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------+----------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked| Title|Title_Rare|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------+----------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|    Mr|  not rare|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|   Mrs|  not rare|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|  Miss|  not rare|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|   Mrs|  not rare|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|    Mr|  not rare|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|    Mr|  not rare|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|    Mr|  not rare|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|Master|  not rare|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|   Mrs|  not rare|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|   Mrs|  not rare|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|  Miss|  not rare|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|  Miss|  not rare|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|    Mr|  not rare|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|    Mr|  not rare|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|  Miss|  not rare|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|   Mrs|  not rare|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|Master|  not rare|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|    Mr|  not rare|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|   Mrs|  not rare|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|   Mrs|  not rare|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@udf(returnType=StringType()) \n",
    "def impute_title(title):\n",
    "    return titles_map[title]# Title_map is your dictionary. please change this name with your dictionary name.\n",
    "\n",
    "combinedWithTitle = combined.withColumn(\"Title_Rare\", impute_title(col(\"Title\")))\n",
    "combinedWithTitle.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sn8ewllf7kiV"
   },
   "source": [
    "**Display \"Title\" from table and group by \"Title\" column:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "id": "J9sjQb084GU6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|   Title|count|\n",
      "+--------+-----+\n",
      "|     Don|    1|\n",
      "|    Miss|  257|\n",
      "|Countess|    2|\n",
      "|     Col|    4|\n",
      "|     Rev|    9|\n",
      "|    Lady|    2|\n",
      "|  Master|   56|\n",
      "|     Mme|    1|\n",
      "|    Capt|    2|\n",
      "|      Mr|  786|\n",
      "|      Dr|   11|\n",
      "|     Mrs|  186|\n",
      "|     Sir|    2|\n",
      "|Jonkheer|    2|\n",
      "|    Mlle|    4|\n",
      "|   Major|    3|\n",
      "|      Ms|    1|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combinedWithTitle.groupBy(\"Title\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-H45QNLj9vJp"
   },
   "source": [
    "## **Preprocessing Age**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XwRAhumK-u__"
   },
   "source": [
    "**Based on the \"age\" column mean, you will fill in the missing age values:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "id": "eXYSVzvl4z63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.079501879699244"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_mean = combinedWithTitle.select(F.mean(\"Age\")).collect()\n",
    "age_mean[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLPivde8_GI-"
   },
   "source": [
    "**Fill missing with \"age\" mean:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "id": "lBgW8aFD90PA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+-------------------------------------------------------+------+------------------+-----+-----+----------------+-------+-----+--------+------+----------+\n",
      "|PassengerId|Survived|Pclass|Name                                                   |Sex   |Age               |SibSp|Parch|Ticket          |Fare   |Cabin|Embarked|Title |Title_Rare|\n",
      "+-----------+--------+------+-------------------------------------------------------+------+------------------+-----+-----+----------------+-------+-----+--------+------+----------+\n",
      "|1          |0       |3     |Braund, Mr. Owen Harris                                |male  |22.0              |1    |0    |A/5 21171       |7.25   |null |S       |Mr    |not rare  |\n",
      "|2          |1       |1     |Cumings, Mrs. John Bradley (Florence Briggs Thayer)    |female|38.0              |1    |0    |PC 17599        |71.2833|C85  |C       |Mrs   |not rare  |\n",
      "|3          |1       |3     |Heikkinen, Miss. Laina                                 |female|26.0              |0    |0    |STON/O2. 3101282|7.925  |null |S       |Miss  |not rare  |\n",
      "|4          |1       |1     |Futrelle, Mrs. Jacques Heath (Lily May Peel)           |female|35.0              |1    |0    |113803          |53.1   |C123 |S       |Mrs   |not rare  |\n",
      "|5          |0       |3     |Allen, Mr. William Henry                               |male  |35.0              |0    |0    |373450          |8.05   |null |S       |Mr    |not rare  |\n",
      "|6          |0       |3     |Moran, Mr. James                                       |male  |30.079501879699244|0    |0    |330877          |8.4583 |null |Q       |Mr    |not rare  |\n",
      "|7          |0       |1     |McCarthy, Mr. Timothy J                                |male  |54.0              |0    |0    |17463           |51.8625|E46  |S       |Mr    |not rare  |\n",
      "|8          |0       |3     |Palsson, Master. Gosta Leonard                         |male  |2.0               |3    |1    |349909          |21.075 |null |S       |Master|not rare  |\n",
      "|9          |1       |3     |Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)      |female|27.0              |0    |2    |347742          |11.1333|null |S       |Mrs   |not rare  |\n",
      "|10         |1       |2     |Nasser, Mrs. Nicholas (Adele Achem)                    |female|14.0              |1    |0    |237736          |30.0708|null |C       |Mrs   |not rare  |\n",
      "|11         |1       |3     |Sandstrom, Miss. Marguerite Rut                        |female|4.0               |1    |1    |PP 9549         |16.7   |G6   |S       |Miss  |not rare  |\n",
      "|12         |1       |1     |Bonnell, Miss. Elizabeth                               |female|58.0              |0    |0    |113783          |26.55  |C103 |S       |Miss  |not rare  |\n",
      "|13         |0       |3     |Saundercock, Mr. William Henry                         |male  |20.0              |0    |0    |A/5. 2151       |8.05   |null |S       |Mr    |not rare  |\n",
      "|14         |0       |3     |Andersson, Mr. Anders Johan                            |male  |39.0              |1    |5    |347082          |31.275 |null |S       |Mr    |not rare  |\n",
      "|15         |0       |3     |Vestrom, Miss. Hulda Amanda Adolfina                   |female|14.0              |0    |0    |350406          |7.8542 |null |S       |Miss  |not rare  |\n",
      "|16         |1       |2     |Hewlett, Mrs. (Mary D Kingcome)                        |female|55.0              |0    |0    |248706          |16.0   |null |S       |Mrs   |not rare  |\n",
      "|17         |0       |3     |Rice, Master. Eugene                                   |male  |2.0               |4    |1    |382652          |29.125 |null |Q       |Master|not rare  |\n",
      "|18         |1       |2     |Williams, Mr. Charles Eugene                           |male  |30.079501879699244|0    |0    |244373          |13.0   |null |S       |Mr    |not rare  |\n",
      "|19         |0       |3     |Vander Planke, Mrs. Julius (Emelia Maria Vandemoortele)|female|31.0              |1    |0    |345763          |18.0   |null |S       |Mrs   |not rare  |\n",
      "|20         |1       |3     |Masselmani, Mrs. Fatima                                |female|30.079501879699244|0    |0    |2649            |7.225  |null |C       |Mrs   |not rare  |\n",
      "+-----------+--------+------+-------------------------------------------------------+------+------------------+-----+-----+----------------+-------+-----+--------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = combinedWithTitle.na.fill(age_mean[0][0],subset = ['Age'])\n",
    "df_cleaned.show(truncate= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGsnUz-m_P95"
   },
   "source": [
    "## **Preprocessing Embarked**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHbbamcXMSYP"
   },
   "source": [
    "**Select \"Embarked\" column, count them, order by count Desc, and save in grouped_Embarked variable:**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "id": "v-lRu5vc_FW7"
   },
   "outputs": [],
   "source": [
    "embarked = df_cleaned.groupBy(\"Embarked\").count().orderBy('count',ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1qf5u2IOQrx"
   },
   "source": [
    "**Show \"groupped_Embarked\" your variable:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "id": "jSFNDTNg_erb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Embarked|count|\n",
      "+--------+-----+\n",
      "|       S|  962|\n",
      "|       C|  253|\n",
      "|       Q|  111|\n",
      "|    null|    3|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embarked.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzQWYgKBMrbp"
   },
   "source": [
    "**Get max of groupped_Embarked:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "id": "ZLYj4F7E_iqb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embarked_max = grouped_Embarked.first()[0]\n",
    "embarked_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8vhoEs8N2w_"
   },
   "source": [
    "**Fill missing values with max 'S' of grouped_Embarked:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "id": "LdzQCRud_mAa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+-----+--------+------+----------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex|               Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked| Title|Title_Rare|\n",
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+-----+--------+------+----------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|              22.0|    1|    0|       A/5 21171|   7.25| null|       S|    Mr|  not rare|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|              38.0|    1|    0|        PC 17599|71.2833|  C85|       C|   Mrs|  not rare|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|              26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|  Miss|  not rare|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|              35.0|    1|    0|          113803|   53.1| C123|       S|   Mrs|  not rare|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|              35.0|    0|    0|          373450|   8.05| null|       S|    Mr|  not rare|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|30.079501879699244|    0|    0|          330877| 8.4583| null|       Q|    Mr|  not rare|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|              54.0|    0|    0|           17463|51.8625|  E46|       S|    Mr|  not rare|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male|               2.0|    3|    1|          349909| 21.075| null|       S|Master|  not rare|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|              27.0|    0|    2|          347742|11.1333| null|       S|   Mrs|  not rare|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|              14.0|    1|    0|          237736|30.0708| null|       C|   Mrs|  not rare|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female|               4.0|    1|    1|         PP 9549|   16.7|   G6|       S|  Miss|  not rare|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|              58.0|    0|    0|          113783|  26.55| C103|       S|  Miss|  not rare|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|              20.0|    0|    0|       A/5. 2151|   8.05| null|       S|    Mr|  not rare|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|              39.0|    1|    5|          347082| 31.275| null|       S|    Mr|  not rare|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|              14.0|    0|    0|          350406| 7.8542| null|       S|  Miss|  not rare|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|              55.0|    0|    0|          248706|   16.0| null|       S|   Mrs|  not rare|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male|               2.0|    4|    1|          382652| 29.125| null|       Q|Master|  not rare|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|30.079501879699244|    0|    0|          244373|   13.0| null|       S|    Mr|  not rare|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|              31.0|    1|    0|          345763|   18.0| null|       S|   Mrs|  not rare|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|30.079501879699244|    0|    0|            2649|  7.225| null|       C|   Mrs|  not rare|\n",
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+-----+--------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = df_cleaned.na.fill(embarked_max, subset=['Embarked'])\n",
    "df_cleaned.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEcdV5Vb_qR_"
   },
   "source": [
    "## **Preprocessing Cabin**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BQzPs7tqhpA"
   },
   "source": [
    "**Replace \"cabin\" column with first char from the string:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "id": "4b6L5pK0_nQz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-----+----------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|Title|Title_Rare|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-----+----------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|   Mr|  not rare|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|    C|       C|  Mrs|  not rare|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S| Miss|  not rare|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1|    C|       S|  Mrs|  not rare|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|   Mr|  not rare|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import substring\n",
    "df_cleaned = df_cleaned.withColumn('Cabin', substring('Cabin', 1, 1))\n",
    "df_cleaned.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzSDsWsUj9Im"
   },
   "source": [
    "**Create the temporary view:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "id": "MR7CXTY7_tMJ"
   },
   "outputs": [],
   "source": [
    "df_cleaned.createOrReplaceTempView(\"DFCLEANED_TEMP_VIEW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gv7lfQFkrLlN"
   },
   "source": [
    "**Select \"Cabin\" column, count \"Cabin\" column, Group by \"Cabin\" column, Order By count DESC**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "id": "A0tZG_mvrKXv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|Cabin|Count|\n",
      "+-----+-----+\n",
      "| null|    0|\n",
      "|    T|    1|\n",
      "|    G|    4|\n",
      "|    F|   18|\n",
      "|    A|   23|\n",
      "|    E|   51|\n",
      "|    D|   52|\n",
      "|    B|   77|\n",
      "|    C|   82|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT Cabin, COUNT(Cabin) as Count FROM DFCLEANED_TEMP_VIEW Group By Cabin ORDER BY Count\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GR6j0LOsB4y"
   },
   "source": [
    "**Fill missing values with \"U\":**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "id": "mwq5CHEz_up_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+-----+--------+------+----------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex|               Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked| Title|Title_Rare|\n",
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+-----+--------+------+----------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|              22.0|    1|    0|       A/5 21171|   7.25|    U|       S|    Mr|  not rare|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|              38.0|    1|    0|        PC 17599|71.2833|    C|       C|   Mrs|  not rare|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|              26.0|    0|    0|STON/O2. 3101282|  7.925|    U|       S|  Miss|  not rare|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|              35.0|    1|    0|          113803|   53.1|    C|       S|   Mrs|  not rare|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|              35.0|    0|    0|          373450|   8.05|    U|       S|    Mr|  not rare|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|30.079501879699244|    0|    0|          330877| 8.4583|    U|       Q|    Mr|  not rare|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|              54.0|    0|    0|           17463|51.8625|    E|       S|    Mr|  not rare|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male|               2.0|    3|    1|          349909| 21.075|    U|       S|Master|  not rare|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|              27.0|    0|    2|          347742|11.1333|    U|       S|   Mrs|  not rare|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|              14.0|    1|    0|          237736|30.0708|    U|       C|   Mrs|  not rare|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female|               4.0|    1|    1|         PP 9549|   16.7|    G|       S|  Miss|  not rare|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|              58.0|    0|    0|          113783|  26.55|    C|       S|  Miss|  not rare|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|              20.0|    0|    0|       A/5. 2151|   8.05|    U|       S|    Mr|  not rare|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|              39.0|    1|    5|          347082| 31.275|    U|       S|    Mr|  not rare|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|              14.0|    0|    0|          350406| 7.8542|    U|       S|  Miss|  not rare|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|              55.0|    0|    0|          248706|   16.0|    U|       S|   Mrs|  not rare|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male|               2.0|    4|    1|          382652| 29.125|    U|       Q|Master|  not rare|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|30.079501879699244|    0|    0|          244373|   13.0|    U|       S|    Mr|  not rare|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|              31.0|    1|    0|          345763|   18.0|    U|       S|   Mrs|  not rare|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|30.079501879699244|    0|    0|            2649|  7.225|    U|       C|   Mrs|  not rare|\n",
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+-----+--------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = df_cleaned.na.fill('U', subset=['Cabin'])\n",
    "df_cleaned.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Cols: ['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked', 'Title', 'Title_Rare']\n",
      "Index Cols: ['Name_index', 'Sex_index', 'Ticket_index', 'Cabin_index', 'Embarked_index', 'Title_index', 'Title_Rare_index']\n",
      "OHE Cols: ['Name_OHE', 'Sex_OHE', 'Ticket_OHE', 'Cabin_OHE', 'Embarked_OHE', 'Title_OHE', 'Title_Rare_OHE']\n"
     ]
    }
   ],
   "source": [
    "categoricalCols = [col for (col, colType) in df_cleaned.dtypes \n",
    "                   if colType == 'string']\n",
    "print(\"Categorical Cols:\", categoricalCols)\n",
    "\n",
    "indexOutputCols = [col +'_index' for col in categoricalCols]\n",
    "print(\"Index Cols:\", indexOutputCols)\n",
    "\n",
    "oheOutputCols = [col +'_OHE' for col in categoricalCols]\n",
    "print(\"OHE Cols:\", oheOutputCols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRnhA_5-0Hi4"
   },
   "source": [
    "**StringIndexer: A label indexer that maps a string column of labels to an ML column of label indices. If the input column is numeric, we cast it to string and index the string values. The indices are in [0, numLabels). By default, this is ordered by label frequencies so the most frequent label gets index 0. The ordering behavior is controlled by setting stringOrderType. Its default value is ‘frequencyDesc’.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RIKlOX71GQ-"
   },
   "source": [
    "**StringIndexer(inputCol=None, outputCol=None)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "id": "odhuI2EHKuCm"
   },
   "outputs": [],
   "source": [
    "stringIndexer = StringIndexer(inputCols = categoricalCols,\n",
    "                              outputCols= indexOutputCols,\n",
    "                             handleInvalid='skip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1DECL9yCK3JZ"
   },
   "source": [
    "**OneHotEncoder(inputCols=None, outputCols=None)**\n",
    "\n",
    "A one-hot encoder that maps a column of category indices to a column of binary vectors, with at most a single one-value per row that indicates the input category index. For example with 5 categories, an input value of 2.0 would map to an output vector of [0.0, 0.0, 1.0, 0.0]. The last category is not included by default (configurable via dropLast), because it makes the vector entries sum up to one, and hence linearly dependent. So an input value of 4.0 maps to [0.0, 0.0, 0.0, 0.0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "id": "tiAjDEy1LBhz"
   },
   "outputs": [],
   "source": [
    "oheEncoder = OneHotEncoder(inputCols=indexOutputCols,\n",
    "                           outputCols=oheOutputCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric Col: ['Age', 'Fare']\n"
     ]
    }
   ],
   "source": [
    "numricCol = [col for (col, colType) in df_cleaned.dtypes\n",
    "            if ((colType=='double')& (col!='crew'))]\n",
    "print('Numeric Col:',numricCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name_OHE',\n",
       " 'Sex_OHE',\n",
       " 'Ticket_OHE',\n",
       " 'Cabin_OHE',\n",
       " 'Embarked_OHE',\n",
       " 'Title_OHE',\n",
       " 'Title_Rare_OHE',\n",
       " 'Age',\n",
       " 'Fare']"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assemeberlInputs = oheOutputCols + numricCol\n",
    "assemeberlInputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1FsiLsd9452v"
   },
   "source": [
    "**VectorAssembler: VectorAssembler(*, inputCols=None, outputCol=None). A feature transformer that merges multiple columns into a vector column.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "id": "BuytKk0hLE6p"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "vecAssembler = VectorAssembler(inputCols=assemeberlInputs, outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dU8DeZfh7JIo"
   },
   "source": [
    "**Use randomSplit function and split data to x_train, and X_test with 80% and 20% Consecutive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "id": "8C11xf1iAzKp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1094 rows in the training set, and 235 in the test set\n"
     ]
    }
   ],
   "source": [
    "# Splitting Data\n",
    "train_df , test_df = df_cleaned.randomSplit([0.8, 0.2] , seed = 42)\n",
    "print(f\"There are {train_df.count()} rows in the training set, and {test_df.count()} in the test set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0c_Hf_b0R12"
   },
   "source": [
    "**Pipeline: ML Pipelines provide a uniform set of high-level APIs built on top of DataFrames that help users create and tune practical machine learning pipelines.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJQvmFai72O7"
   },
   "source": [
    "**Build RandomForestClassifier model and use pipeline to fit and transform then display \"prediction, Survived, features\" columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol='Survived',featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "id": "YnpmZqlTLPGq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|Survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       0.0|       0|(1472,[600,811,11...|\n",
      "|       1.0|       1|(1472,[533,1414,1...|\n",
      "|       0.0|       0|(1472,[684,811,87...|\n",
      "|       1.0|       1|(1472,[515,1225,1...|\n",
      "|       0.0|       1|(1472,[366,811,11...|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Building the pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline =Pipeline(stages = [stringIndexer,oheEncoder,vecAssembler,rf])\n",
    "\n",
    "pipelineModel = pipeline.fit(train_df)\n",
    "predictions = pipelineModel.transform(test_df)\n",
    "predictions.select(\"prediction\", \"Survived\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSXEI8-r8bKY"
   },
   "source": [
    "**Use MulticlassClassificationEvaluator and set the \"labelCol\" to \"Survived\",  \"predictionCol\" to \"prediction\", \"metricName\" to \"accuracy\"** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7972027972027972"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "classificationEvaluator = MulticlassClassificationEvaluator(predictionCol='prediction',\n",
    "                                         labelCol='Survived',\n",
    "                                         metricName='accuracy')\n",
    "accuracy = classificationEvaluator.evaluate(predictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sO6_R1zJ9R1R"
   },
   "source": [
    "**When you are finished send the project via Google classroom**\n",
    "**Please let me know if you have any questions.**\n",
    "* nabieh.mostafa@yahoo.com\n",
    "* +201015197566 (Whatsapp)\n",
    "\n",
    "**Don't Hate me, I push you to learn**\n",
    "\n",
    "**I will help you to become an awesome data engineer.**\n",
    "\n",
    "**Why did I say that \"Data Engineer\"?**\n",
    "\n",
    "**Tricky question, but an optional question, if you would like to know the answer, ask me.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Practical_work.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
